---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- <style>
  /* CSS for the Pill Badges */
  .paper-badge {
    display: inline-block;
    padding: 2px 8px;
    margin-left: 6px;
    font-size: 0.75rem;
    font-weight: 600;
    color: #444;
    background-color: #f1f3f5;
    border: 1px solid #e1e4e8;
    border-radius: 12px;
    text-decoration: none !important; /* Forces no underline */
    vertical-align: middle;
    transition: all 0.2s ease;
  }
  
  .paper-badge:hover {
    background-color: #e1e4e8;
    color: #000;
    transform: translateY(-1px);
    text-decoration: none;
  }
  
  .award-badge {
  display: inline-block;
  padding: 2px 8px;
  margin-left: 6px;
  font-size: 0.75rem;
  font-weight: 600;
  color: #c92a2a;            /* Dark red text */
  background-color: #ffe3e3; /* Light pink/red background */
  border: 1px solid #ffa8a8; /* Subtle red border */
  border-radius: 12px;
  vertical-align: middle;
}
</style> -->

<style>
  /* 1. Modern Font Settings */
  body, h1, h2, h3, h4, h5, h6, p, li, a {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
  }

  /* Optional: Add a little breathing room to text */
  p, li {
    line-height: 1.6;
  }

  /* --- BADGE STYLING --- */

  /* Shared structure: This guarantees they look identical in size/shape */
  .paper-badge, .award-badge {
    display: inline-block;
    padding: 2px 8px;
    margin-left: 6px;
    font-size: 0.75rem;
    font-weight: 600;
    border-radius: 12px;
    vertical-align: middle;
    line-height: 1.2; /* Ensures consistency between links and plain text spans */
    border: 1px solid transparent; /* Placeholder border to keep sizing even */
  }

  /* The Gray PDF Link style (Kept your preferred colors) */
  .paper-badge {
    color: #444;
    background-color: #f1f3f5;
    border-color: #e1e4e8;
    text-decoration: none !important;
    transition: all 0.2s ease;
  }

  /* Hover effect only for the PDF links */
  .paper-badge:hover {
    background-color: #e1e4e8;
    color: #000;
    transform: translateY(-1px);
  }

  /* The Red Award style */
  .award-badge {
    color: #c92a2a;
    background-color: #ffe3e3;
    border-color: #ffa8a8;
    cursor: default; /* Indicates it's not clickable */
  }
</style>


<p style="color:#000000;">
I'm a <strong>Research Scientist</strong> at <b><a href="https://deepmind.google" style="color: black;text-decoration: none">Google DeepMind</a></b> working on improving Gemini's fundamental capabilities for retrieval and ranking. 
</p>

<p style="color:#000000;">
I completed my Ph.D. in <b><a href="https://lsa.umich.edu/stats" style="color: black;text-decoration: none">Statistics</a></b> at the <b><a href="https://umich.edu/" style="color: black;text-decoration: none">University of Michigan</a></b> in 2025, where I was fortunate to be advised by <b><a href="https://ambujtewari.github.io" style="color: black;text-decoration: none">Ambuj Tewari</a></b>. My Ph.D. was graciously supported by the <b><a href="https://www.nsfgrfp.org" style="color: black;text-decoration: none">National Science Foundation Graduate Research Fellowship (NSF GRFP)</a></b> and the <b><a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2025" style="color: black;text-decoration: none"> 2025 Apple Scholars in AI/ML PhD Fellowship</a></b>. Prior to my Ph.D, I double-majored in <b><a href="https://cse.engin.umich.edu/" style="color: black;text-decoration: none">Computer Science</a></b> and <b><a href="https://che.engin.umich.edu/" style="color: black;text-decoration: none">Chemical Engineering</a></b> and worked with <b><a href="https://mahdi.ch" style="color: black;text-decoration: none">Mahdi Cheraghchi</a></b>, <b><a href="https://web.eecs.umich.edu/~skutty/" style="color: black;text-decoration: none">Sindhu Kutty</a></b>, and <b><a href="https://lenert.engin.umich.edu" style="color: black;text-decoration: none">Andrej Lenert</a></b>. 
</p>

<p style="color:#000000;">
My research interests lie in the <strong>Foundations of Machine Learning</strong>. During my Ph.D, I worked on various topics in learning theory, including online learning, adversarial robustness, differential privacy, and language generation, among other things. Nowadays, I work on <strong>post-training</strong> for large language models, particularly <strong>reasoning</strong> and <strong>adaptive inference-time compute</strong>. 
</p>

<p style="color:#000000;">
Apart from research and work, I am a fan of bodybuilding and actively keep up with the <b><a href="https://mrolympia.com" style="color: black;text-decoration: none">Mr. Olympia</a></b>.
</p>


<details>
<summary><h1 style="color: black; display:inline-block; cursor:pointer;">Preprints</h1></summary>
<ol>
<li><b>Estimating the (Un)seen: Sample-dependent Mass Estimation</b> <a href="https://drive.google.com/file/d/18z-DqgBSlZ8jpujniqn3MedjLYBvT4Zp/view?usp=share_link" class="paper-badge">PDF</a><br>
    with <a href="https://vtaly.net" style="color: black;">Vitaly Feldman</a>, <a href="https://www.satyenkale.com" style="color: black;">Satyen Kale</a>, <a href="http://kunaltalwar.org" style="color: black;">Kunal Talwar</a>, and <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Preprint</i>, 2025.</li>
<li><b>Transductive and Learning-Augmented Online Regression</b> <a href="http://arxiv.org/abs/2510.03917" class="paper-badge">PDF</a><br>
   with <a href="https://sites.google.com/view/shenghaoxie/" style="color: black;"> Shenghao Xie </a>, <a href="https://samsonzhou.github.io" style="color: black;"> Samson Zhou </a><br>
    <i>Preprint</i>, 2025.</li>
<li><b>Online Boosting for Multilabel Ranking with Top-k Feedback</b> <a href="https://arxiv.org/abs/1910.10937" class="paper-badge">PDF</a><br>
    with Daniel T. Zhang, Young Hun Jung, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Preprint</i>, 2020.</li>
</ol>
</details>

<details open>
<summary><h1 style="color: black; display:inline-block; cursor:pointer;">In Submission</h1></summary>
<ol>
<li><b>On Generation in Metric Spaces</b> <a href="https://www.arxiv.org/abs/2602.07710" class="paper-badge">PDF</a><br>
    with <a href="https://jiaxun-li.github.io" style="color: black;"> Jiaxun Li </a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>In Submission</i>, 2026.</li>
 <li><b>Optimal Stopping vs Best-of-N for Inference Time Optimization</b> <a href="https://arxiv.org/abs/2510.01394" class="paper-badge">PDF</a><br>
   with <a href="https://yhkalayci.github.io" style="color: black;"> Yusuf Kalayci </a>, <a href="https://viterbi-web.usc.edu/~shaddin/" style="color: black;"> Shaddin Dughmi </a><br>
    <i>In Submission</i>, 2026.</li>
 <li><b>AdaBoN: Adaptive Best-of-N Alignment</b> <a href="https://arxiv.org/abs/2505.12050" class="paper-badge">PDF</a><br>
    with <a href="https://web.stanford.edu/~asi/" style="color: black;"> Hilal Asi </a>, <a href="https://www.satyenkale.com" style="color: black;"> Satyen Kale </a><br>
    <i>In Submission</i>, 2026.</li>
<li><b>AI-rithmetic</b> <a href="https://www.arxiv.org/abs/2602.10416" class="paper-badge">PDF</a><br>
    with <a href="https://alexbie98.github.io/" style="color: black;">Alex Bie</a>, <a href="https://travisbarrydick.github.io/" style="color: black;">Travis Dick</a>, <a href="https://scholar.google.com/citations?user=2OUGYFAAAAAJ&hl=en" style="color: black;">Alex Kulesza</a>, <a href="https://research.google/people/prabhakarraghavan/?&type=google" style="color: black;">Prabhakar Raghavan</a>, <a href="https://theory.stanford.edu/~sergei/" style="color: black;">Sergei Vassilvitskii</a> <br>
    <i>In Submission</i>, 2026.</li>
</ol>
</details>

<details open>
<summary><h1 style="color: black; margin-bottom: 15px; display:inline-block; cursor:pointer;">Publications</h1></summary>

  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer; margin-top: 0px;">Language Generation</h3></summary>
  <ol>
  <li><b>Learning to Choose or Choosing to Learn: Best-of-N vs. Supervised Fine-Tuning for Bit String Generation</b> <a href="http://arxiv.org/abs/2505.17288" class="paper-badge">PDF</a><br>
     with <a href="https://somerstep.github.io" style="color: black;"> Seamus Somerstep </a>, <a href="https://unique-subedi.github.io" style="color: black;"> Unique Subedi </a>,<a href="https://yuekai.github.io" style="color: black;"> Yuekai Sun </a><br>
      <i>Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2026.<br>
     also at <i>Conference on the Mathematical Theory of Deep Neural Networks (DeepMath)</i>, 2025.</li>
      
  <li><b>Generation through the lens of learning theory</b> <a href="https://arxiv.org/abs/2410.13714" class="paper-badge">PDF</a><br>
      with <a href="https://jiaxun-li.github.io" style="color: black;"> Jiaxun Li </a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Learning Theory (COLT)</i>, 2025.</li>
     
  <li><b>Representative Language Generation</b> <a href="http://arxiv.org/abs/2505.21819" class="paper-badge">PDF</a><br>
      with <a href="https://cpeale.github.io" style="color: black;"> Charlotte Peale </a>, <a href="https://omereingold.wordpress.com" style="color: black;">Omer Reingold</a><br>
      <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
      
  <li><b>Generation from Noisy Examples</b> <a href= "https://arxiv.org/abs/2501.04179" class="paper-badge">PDF</a><br>
      with <a href= "https://scholar.google.com/citations?user=GpisoW8AAAAJ&hl=en" style="color: black;"> Ananth Raman </a><br>
      <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
  </ol>
  </details>


  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer;">Differential Privacy</h3></summary>
  <ol start="5">
  <li><b>Missing Mass for Differentially Private Domain Discovery</b> <span class="award-badge">Oral</span> <a href="https://drive.google.com/file/d/1UHKCF9krT0khLvxWLvC0HJojKx4PcScF/view?usp=sharing" class="paper-badge">PDF</a><br>
     with <a href="https://www.majos.net" style="color: black;"> Matthew Joseph </a>, <a href="https://travisbarrydick.github.io" style="color: black;"> Travis Dick </a><br>
      <i>International Conference on Learning Representations (ICLR)</i>, 2026.</li>
     
  <li><b>Tracking the Best Expert Privately</b> <a href="https://arxiv.org/abs/2503.09889" class="paper-badge">PDF</a><br>
      with <a href="https://web.stanford.edu/~asi/" style="color: black;"> Hilal Asi </a>, <a href="https://aadirupa.github.io" style="color: black;">Aadirupa Saha</a><br>
      <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
     
  <li><b>Faster Rates for Private Adversarial Bandits</b> <a href="http://arxiv.org/abs/2505.21790" class="paper-badge">PDF</a><br>
      with <a href="https://web.stanford.edu/~asi/" style="color: black;">Hilal Asi</a>, <a href="http://kunaltalwar.org" style="color: black;">Kunal Talwar</a><br>
      <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
  </ol>
  </details>


  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer;">Beyond Worst-case Guarantees for Learning</h3></summary>
  <ol start="8">
  <li><b>Online Classification with Predictions</b> <a href="http://arxiv.org/abs/2405.14066" class="paper-badge">PDF</a><br>
      with <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024.</li>
     
  <li><b>Smoothed Online Classification can be Harder than Batch Classification</b> <a href="https://arxiv.org/pdf/2405.15424" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024.</li>
     
  <li><b>Multiclass Transductive Online Learning</b> <span class="award-badge">Spotlight</span> <a href="http://arxiv.org/abs/2411.01634" class="paper-badge">PDF</a><br>
      with <a href="https://stevehanneke.com" style="color: black;">Steve Hanneke</a>, <a href="https://scholar.google.com/citations?user=nRTM5b8AAAAJ&hl=en" style="color: black;">Amirreza Shaeiri</a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a><br>
      <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024.</li>
  
  <li><b>On Proper Learnability between Average- and Worst-case Robustness</b> <a href="https://arxiv.org/abs/2211.05656" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2023.</li>
  </ol>
  </details>


  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer;">Online Learning</h3></summary>
  <ol start="12">
  <li><b>The Complexity of Sequential Prediction in Dynamical Systems</b> <span class="award-badge">Oral</span> <a href="https://arxiv.org/abs/2402.06614" class="paper-badge">PDF</a><br>
     with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
     <i>Conference on Learning for Dynamics and Control (L4DC)</i>, 2025.</li>
     
  <li><b>A Unified Theory of Supervised Online Learnability</b> <span class="award-badge">Outstanding Paper</span><a href="https://arxiv.org/abs/2307.03816" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Algorithmic Learning Theory (ALT)</i>, 2025.</li>
      
  <li><b>Online Learning with Set-Valued Feedback</b> <a href="https://arxiv.org/abs/2306.06247" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Learning Theory (COLT)</i>, 2024.</li>
      
  <li><b>Online Infinite-Dimensional Regression: Learning Linear Operators</b> <a href="https://arxiv.org/abs/2309.06548" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Algorithmic Learning Theory (ALT)</i>, 2024.</li>
      
  <li><b>Multiclass Online Learning and Uniform Convergence</b> <a href="https://arxiv.org/abs/2303.17716" class="paper-badge">PDF</a><br>
     with <a href="https://stevehanneke.com" style="color: black;">Steve Hanneke</a>, <a href="https://csaws.cs.technion.ac.il/~shaymrn/" style="color: black;">Shay Moran</a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Learning Theory (COLT)</i>, 2023.</li>
      
  <li><b>Online Agnostic Multiclass Boosting</b> <a href="https://arxiv.org/abs/2205.15113" class="paper-badge">PDF</a><br>
      with <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2022.</li>
  </ol>
  </details>


  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer;">Partial Feedback</h3></summary>
  <ol start="18">
  <li><b>Apple Tasting: Combinatorial Dimensions and Minimax Rates</b> <a href="https://arxiv.org/abs/2310.19064" class="paper-badge">PDF</a><br>
      with <a href= "https://scholar.google.com/citations?user=GpisoW8AAAAJ&hl=en" style="color: black;"> Ananth Raman </a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Learning Theory (COLT)</i>, 2024.</li>
      
  <li><b>Multiclass Online Learnability under Bandit Feedback</b> <a href="https://arxiv.org/abs/2308.04620" class="paper-badge">PDF</a><br>
      with <a href= "https://scholar.google.com/citations?user=GpisoW8AAAAJ&hl=en" style="color: black;"> Ananth Raman </a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://idanmehalel.wordpress.com" style="color: black;">Idan Mehalel</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Algorithmic Learning Theory (ALT)</i>, 2024.</li>
  </ol>
  </details>


  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer;">Multioutput Learning</h3></summary>
  <ol start="20">
  <li><b>A Characterization of Multioutput Learnability</b> <a href="https://arxiv.org/abs/2301.02729" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Journal of Machine Learning Research (JMLR)</i>, 2024.</li>
      
  <li><b>On the Learnability of Multilabel Ranking</b> <span class="award-badge">Spotlight</span><a href="https://arxiv.org/abs/2304.03337" class="paper-badge">PDF</a><br>
      with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
      <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2023.</li>
  </ol>
  </details>


  <details open style="margin-left: 15px;">
  <summary><h3 style="display:inline-block; cursor:pointer;">Other</h3></summary>
  <ol start="22">
  <li><b>Design of thermophotovoltaics for tolerance of parasitic absorption</b> <a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-27-22-31757&id=422403" class="paper-badge">PDF</a><br>
      with Tobias Burger, <a href="https://lenert.engin.umich.edu" style="color: black;">Andrej Lenert</a><br>
      <i>Optics Express</i>, 2019.</li>
  </ol>
  </details>

</details>

<!-- <details>
<summary>
  <h1 style="display:inline-block; cursor:pointer; color: black; margin-top: 60px;">Talks</h1>
</summary>

<ul>
<li>Optimal Stopping vs Best-of-N for Inference Time Optimization (Percepta Job Talk 2025) <a href="https://drive.google.com/file/d/1EPaksfpvEWg-ZWJLz1N57SSlAThaR1Bs/view?usp=sharing" class="paper-badge">Slides</a></li>
<li>Optimal Stopping vs Best-of-N for Inference Time Optimization (Google DeepMind Tech Talk 2025) <a href="https://drive.google.com/file/d/1EPaksfpvEWg-ZWJLz1N57SSlAThaR1Bs/view?usp=sharing" class="paper-badge">Slides</a></li>
<li>A Unified Theory of Supervised Online Learnability (ALT 2025)</li>
<li>Generation through the lens of learning theory (Apple 2025)</li>
<li>Generation through the lens of learning theory (NEU CS Theory Seminar) <a href="https://drive.google.com/file/d/1mfKRbMvGWCDnhhpQbb8RzUDKqRM4hwas/view?usp=share_link" class="paper-badge">Slides</a></li>
<li>Generation through the lens of learning theory (STATS 700 Guest Lecture)</li>
<li>Trichotomies in Online Learnability (Student ML Research Seminar 2024) <a href="https://drive.google.com/file/d/15R-_OTPSbOuGVLGxcwN0N2HQSeK13u8U/view?usp=sharing" class="paper-badge">Slides</a></li>
<li>Trichotomies in Online Learnability (Apple 2024) <a href="https://drive.google.com/file/d/15R-_OTPSbOuGVLGxcwN0N2HQSeK13u8U/view?usp=sharing" class="paper-badge">Slides</a></li>
<li>Revisiting the Learnability of Apple Tasting (MSSISS 2024)</li>
<li>Multiclass Online Learnability under Bandit Feedback (ALT 2024)</li>
<li>Multiclass Online Learning and Uniform Convergence (UM EECS Theory Seminar) <a href="https://drive.google.com/file/d/1YYH1xC_CDVVpjrbjUNPXMQvojB6XomtV/view?usp=sharing" class="paper-badge">Slides</a></li>
<li>On Classification-Calibration of Gamma-Phi Losses (COLT 2023) <a href="https://drive.google.com/file/d/1odpiQMefHoLJbHs6HLIpS6e0wM8FKEzs/view?usp=sharing" class="paper-badge">Slides</a></li>
</ul>
</details> -->
