---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Research Scientist at <b><a href="https://deepmind.google" style="color: black;text-decoration: none">Google DeepMind</a></b> working on improving Gemini's fundamental capabilities for retrieval and ranking. 

I completed my Ph.D. in <b><a href="https://lsa.umich.edu/stats" style="color: black;text-decoration: none">Statistics</a></b> at the <b><a href="https://umich.edu/" style="color: black;text-decoration: none">University of Michigan</a></b>, where I was fortunate to be advised by <b><a href="https://ambujtewari.github.io" style="color: black;text-decoration: none">Ambuj Tewari</a></b>. My Ph.D. was graciously supported by the <b><a href="https://www.nsfgrfp.org" style="color: black;text-decoration: none">National Science Foundation Graduate Research Fellowship (NSF GRFP)</a></b> and the <b><a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2025" style="color: black;text-decoration: none"> 2025 Apple Scholars in AI/ML PhD Fellowship</a></b>. Prior to my Ph.D, I double-majored in <b><a href="https://cse.engin.umich.edu/" style="color: black;text-decoration: none">Computer Science</a></b> and <b><a href="https://che.engin.umich.edu/" style="color: black;text-decoration: none">Chemical Engineering</a></b> also at UofM where I worked with <b><a href="https://mahdi.ch" style="color: black;text-decoration: none">Mahdi Cheraghchi</a></b>, <b><a href="https://web.eecs.umich.edu/~skutty/" style="color: black;text-decoration: none">Sindhu Kutty</a></b>, and <b><a href="https://lenert.engin.umich.edu" style="color: black;text-decoration: none">Andrej Lenert</a></b>. 

<p style="color:#000000;">
Beyond work, my research interests lie in the <strong>Foundations of Machine Learning</strong>. During my Ph.D, I worked on online learning, learning with complex label spaces, and differential privacy, among other things. Currently, I am interested in all aspects of <strong>post-training</strong> for large language models, particularly reasoning and adaptive compute. 
</p>


<h1 style="color: black;">Preprints</h1>

<ol>
<li><b><a href="https://drive.google.com/file/d/18z-DqgBSlZ8jpujniqn3MedjLYBvT4Zp/view?usp=share_link" style="color: black;text-decoration: none">Estimating the (Un)seen: Sample-dependent Mass Estimation </a></b><br>
    with <a href="https://vtaly.net" style="color: black;">Vitaly Feldman</a>, <a href="https://www.satyenkale.com" style="color: black;">Satyen Kale</a>, <a href="http://kunaltalwar.org" style="color: black;">Kunal Talwar</a>, and <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Preprint</i>, 2025.</li>
<li><b><a href="http://arxiv.org/abs/2510.03917" style="color: black;text-decoration: none">  Transductive and Learning-Augmented Online Regression </a></b><br>
   with <a href="https://sites.google.com/view/shenghaoxie/" style="color: black;"> Shenghao Xie </a>, <a href="https://samsonzhou.github.io" style="color: black;"> Samson Zhou </a><br>
    <i>In Submission</i>, 2025.</li>
<li><b><a href="https://arxiv.org/abs/1910.10937" style="color: black;text-decoration: none">Online Boosting for Multilabel Ranking with Top-k Feedback</a></b><br>
    with Daniel T. Zhang, Young Hun Jung, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Preprint</i>, 2020.</li>
</ol>

<h1 style="color: black;">In Submission</h1>

<ol>
 <li><b><a href="https://arxiv.org/abs/2510.01394" style="color: black;text-decoration: none"> Optimal Stopping vs Best-of-N for Inference Time Optimization </a></b><br>
   with <a href="https://yhkalayci.github.io" style="color: black;"> Yusuf Kalayci </a>, <a href="https://viterbi-web.usc.edu/~shaddin/" style="color: black;"> Shaddin Dughmi </a><br>
    <i>In Submission</i>, 2026.</li>
 <li><b><a href="https://arxiv.org/abs/2505.12050" style="color: black;text-decoration: none">AdaBoN: Adaptive Best-of-N Alignment</a></b><br>
    with <a href="https://web.stanford.edu/~asi/" style="color: black;"> Hilal Asi </a>, <a href="https://www.satyenkale.com" style="color: black;"> Satyen Kale </a><br>
    <i>In Submission</i>, 2026.</li>
<li><b>AI-rithmetic</b><br>
    with <a href="https://alexbie98.github.io/" style="color: black;">Alex Bie</a>, <a href="https://travisbarrydick.github.io/" style="color: black;">Travis Dick</a>, <a href="https://scholar.google.com/citations?user=2OUGYFAAAAAJ&hl=en" style="color: black;">Alex Kulesza</a>, <a href="https://research.google/people/prabhakarraghavan/?&type=google" style="color: black;">Prabhakar Raghavan</a>, <a href="https://theory.stanford.edu/~sergei/" style="color: black;">Sergei Vassilvitskii</a> <br>
    <i>In Submission</i>, 2026.</li>
</ol>
    

<h1 style="color: black;">Publications</h1>
<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Language Generation</h3></summary>
<ol>
<li><b><a href="http://arxiv.org/abs/2505.17288" style="color: black;text-decoration: none">Learning to Choose or Choosing to Learn: Best-of-N vs. Supervised Fine-Tuning for Bit String Generation </a></b><br>
   with <a href="https://somerstep.github.io" style="color: black;"> Seamus Somerstep </a>, <a href="https://unique-subedi.github.io" style="color: black;"> Unique Subedi </a>,<a href="https://yuekai.github.io" style="color: black;"> Yuekai Sun </a><br>
    <i>Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2026.<br>
   also at <i>Conference on the Mathematical Theory of Deep Neural Networks (DeepMath)</i>, 2025.</li>
    
<li><b><a href="https://arxiv.org/abs/2410.13714" style="color: black;text-decoration: none">Generation through the lens of learning theory</a></b><br>
    with <a href="https://jiaxun-li.github.io" style="color: black;"> Jiaxun Li </a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Learning Theory (COLT)</i>, 2025.</li>
   
<li><b><a href="http://arxiv.org/abs/2505.21819" style="color: black;text-decoration: none"> Representative Language Generation</a></b><br>
    with <a href="https://cpeale.github.io" style="color: black;"> Charlotte Peale </a>, <a href="https://omereingold.wordpress.com" style="color: black;">Omer Reingold</a><br>
    <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
    
<li><b><a href= "https://arxiv.org/abs/2501.04179" style="color: black;text-decoration: none"> Generation from Noisy Examples </a></b><br>
    with <a href= "https://scholar.google.com/citations?user=GpisoW8AAAAJ&hl=en" style="color: black;"> Ananth Raman </a><br>
    <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
</ol>
</details>


<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Differential Privacy</h3></summary>
<ol start="5">
<li><b> Missing Mass for Differentially Private Domain Discovery </b><br>
   with <a href="https://www.majos.net" style="color: black;"> Matthew Joseph </a>, <a href="https://travisbarrydick.github.io" style="color: black;"> Travis Dick </a><br>
    <i>International Conference on Learning Representations (ICLR)</i>, 2026.</li>
   
<li><b><a href="https://arxiv.org/abs/2503.09889" style="color: black;text-decoration: none">Tracking the Best Expert Privately</a></b><br>
    with <a href="https://web.stanford.edu/~asi/" style="color: black;"> Hilal Asi </a>, <a href="https://aadirupa.github.io" style="color: black;">Aadirupa Saha</a><br>
    <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
   
<li><b><a href="http://arxiv.org/abs/2505.21790" style="color: black;text-decoration: none">Faster Rates for Private Adversarial Bandits</a></b><br>
    with <a href="https://web.stanford.edu/~asi/" style="color: black;">Hilal Asi</a>, <a href="http://kunaltalwar.org" style="color: black;">Kunal Talwar</a><br>
    <i>International Conference on Machine Learning (ICML)</i>, 2025.</li>
</ol>
</details>


<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Beyond Worst-case Guarantees for Learning</h3></summary>
<ol start="8">
<li><b><a href="http://arxiv.org/abs/2405.14066" style="color: black;text-decoration: none">Online Classification with Predictions</a></b><br>
    with <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024.</li>
   
<li><b><a href="https://arxiv.org/pdf/2405.15424" style="color: black;text-decoration: none">Smoothed Online Classification can be Harder than Batch Classification</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024.</li>
   
<li><b><a href="http://arxiv.org/abs/2411.01634" style="color: black;text-decoration: none">Multiclass Transductive Online Learning</a></b><br>
    with <a href="https://stevehanneke.com" style="color: black;">Steve Hanneke</a>, <a href="https://scholar.google.com/citations?user=nRTM5b8AAAAJ&hl=en" style="color: black;">Amirreza Shaeiri</a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a><br>
    <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2024. <span style="color: red">Spotlight.</span></li>

<li><b><a href="https://arxiv.org/abs/2211.05656" style="color: black;text-decoration: none">On Proper Learnability between Average- and Worst-case Robustness</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2023.</li>
</ol>
</details>


<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Online Learning</h3></summary>
<ol start="12">
<li><b><a href = "https://arxiv.org/abs/2402.06614" style="color: black;text-decoration: none">The Complexity of Sequential Prediction in Dynamical Systems</a></b><br>
   with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
   <i>Conference on Learning for Dynamics and Control (L4DC)</i>, 2025. <span style="color: red">Oral Presentation.</span></li>
   
<li><b><a href="https://arxiv.org/abs/2307.03816" style="color: black;text-decoration: none">A Unified Theory of Supervised Online Learnability</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Algorithmic Learning Theory (ALT)</i>, 2025. <span style="color: red">Outstanding Paper Award.</span></li>
    
<li><b><a href="https://arxiv.org/abs/2306.06247" style="color: black;text-decoration: none">Online Learning with Set-Valued Feedback</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Learning Theory (COLT)</i>, 2024.</li>
    
<li><b><a href="https://arxiv.org/abs/2309.06548" style="color: black;text-decoration: none">Online Infinite-Dimensional Regression: Learning Linear Operators</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Algorithmic Learning Theory (ALT)</i>, 2024.</li>
    
<li><b><a href="https://arxiv.org/abs/2303.17716" style="color: black;text-decoration: none">Multiclass Online Learning and Uniform Convergence</a></b><br>
   with <a href="https://stevehanneke.com" style="color: black;">Steve Hanneke</a>, <a href="https://csaws.cs.technion.ac.il/~shaymrn/" style="color: black;">Shay Moran</a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Learning Theory (COLT)</i>, 2023.</li>
    
<li><b><a href="https://arxiv.org/abs/2205.15113" style="color: black;text-decoration: none">Online Agnostic Multiclass Boosting</a></b><br>
    with <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2022.</li>
</ol>
</details>


<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Partial Feedback</h3></summary>
<ol start="18">
<li><b><a href="https://arxiv.org/abs/2310.19064" style="color: black;text-decoration: none">Apple Tasting: Combinatorial Dimensions and Minimax Rates</a></b><br>
    with <a href= "https://scholar.google.com/citations?user=GpisoW8AAAAJ&hl=en" style="color: black;"> Ananth Raman </a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Learning Theory (COLT)</i>, 2024.</li>
    
<li><b><a href="https://arxiv.org/abs/2308.04620" style="color: black;text-decoration: none">Multiclass Online Learnability under Bandit Feedback</a></b><br>
    with <a href= "https://scholar.google.com/citations?user=GpisoW8AAAAJ&hl=en" style="color: black;"> Ananth Raman </a>, <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://idanmehalel.wordpress.com" style="color: black;">Idan Mehalel</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Algorithmic Learning Theory (ALT)</i>, 2024.</li>
</ol>
</details>


<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Multioutput Learning</h3></summary>
<ol start="20">
<li><b><a href="https://arxiv.org/abs/2301.02729" style="color: black;text-decoration: none">A Characterization of Multioutput Learnability</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Journal of Machine Learning Research (JMLR)</i>, 2024.</li>
    
<li><b><a href="https://arxiv.org/abs/2304.03337" style="color: black;text-decoration: none">On the Learnability of Multilabel Ranking</a></b><br>
    with <a href="https://unique-subedi.github.io" style="color: black;">Unique Subedi</a>, <a href="https://ambujtewari.github.io" style="color: black;">Ambuj Tewari</a><br>
    <i>Conference on Neural Information Processing Systems (NeurIPS)</i>, 2023. <span style="color: red">Spotlight.</span></li>
</ol>
</details>


<details>
<summary><h3 style="display:inline-block; cursor:pointer;">Other</h3></summary>
<ol start="22">
<li><b><a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-27-22-31757&id=422403" style="color: black;text-decoration: none">Design of thermophotovoltaics for tolerance of parasitic absorption</a></b><br>
    with Tobias Burger, <a href="https://lenert.engin.umich.edu" style="color: black;">Andrej Lenert</a><br>
    <i>Optics Express</i>, 2019.</li>
</ol>
</details>


<h1 style="color: black; margin-top: 60px;">Talks</h1>

- Optimal Stopping vs Best-of-N for Inference Time Optimization (Percepta Job Talk 2025) [<b><a href="https://drive.google.com/file/d/1EPaksfpvEWg-ZWJLz1N57SSlAThaR1Bs/view?usp=sharing"  style="color: black;text-decoration: none">slides</a></b>] 
- Optimal Stopping vs Best-of-N for Inference Time Optimization (Google DeepMind Tech Talk 2025) [<b><a href="https://drive.google.com/file/d/1EPaksfpvEWg-ZWJLz1N57SSlAThaR1Bs/view?usp=sharing"  style="color: black;text-decoration: none">slides</a></b>] 
- A Unified Theory of Supervised Online Learnability (ALT 2025)
- Generation through the lens of learning theory (Apple 2025)
- Generation through the lens of learning theory (NEU CS Theory Seminar) [<b><a href="https://drive.google.com/file/d/1mfKRbMvGWCDnhhpQbb8RzUDKqRM4hwas/view?usp=share_link" style="color: black;text-decoration: none">slides</a></b>]
- Generation through the lens of learning theory (STATS 700 Guest Lecture)
- Trichotomies in Online Learnability (Student ML Research Seminar 2024)  [<b><a href="https://drive.google.com/file/d/15R-_OTPSbOuGVLGxcwN0N2HQSeK13u8U/view?usp=sharing
" style="color: black;text-decoration: none">slides</a></b>]
- Trichotomies in Online Learnability (Apple 2024)  [<b><a href="https://drive.google.com/file/d/15R-_OTPSbOuGVLGxcwN0N2HQSeK13u8U/view?usp=sharing
" style="color: black;text-decoration: none">slides</a></b>]
- Revisiting the Learnability of Apple Tasting (MSSISS 2024)
- Multiclass Online Learnability under Bandit Feedback (ALT 2024)
- Multiclass Online Learning and Uniform Convergence (UM EECS Theory Seminar)  [<b><a href="https://drive.google.com/file/d/1YYH1xC_CDVVpjrbjUNPXMQvojB6XomtV/view?usp=sharing" style="color: black;text-decoration: none">slides</a></b>]
- On Classification-Calibration of Gamma-Phi Losses (COLT 2023) [<b><a href="https://drive.google.com/file/d/1odpiQMefHoLJbHs6HLIpS6e0wM8FKEzs/view?usp=sharing" style="color: black;text-decoration: none">slides</a></b>]

<h1 style="color: black;">Hobbies</h1>

Apart from research, I am a fan of bodybuilding and actively keep up with the <b><a href="https://mrolympia.com" style="color: black;text-decoration: none">Mr. Olympia</a></b>.
